@article{DBLP:journals/corr/abs-1905-05304,
  author    = {George B. Mertzios and
               Hendrik Molter and
               Rolf Niedermeier and
               Viktor Zamaraev and
               Philipp Zschoche},
  title     = {Computing Maximum Matchings in Temporal Graphs},
  journal   = {CoRR},
  volume    = {abs/1905.05304},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.05304},
  archivePrefix = {arXiv},
  eprint    = {1905.05304},
  timestamp = {Tue, 28 May 2019 12:48:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-05304.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{gao2018properties,
      title={On the Properties of the Softmax Function with Application in Game Theory and Reinforcement Learning}, 
      author={Bolin Gao and Lacra Pavel},
      year={2018},
      eprint={1704.00805},
      archivePrefix={arXiv},
      primaryClass={math.OC}
}

@article{DBLP:journals/corr/NarayananCVCLJ17,
  author    = {Annamalai Narayanan and
               Mahinthan Chandramohan and
               Rajasekar Venkatesan and
               Lihui Chen and
               Yang Liu and
               Shantanu Jaiswal},
  title     = {graph2vec: Learning Distributed Representations of Graphs},
  journal   = {CoRR},
  volume    = {abs/1707.05005},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.05005},
  archivePrefix = {arXiv},
  eprint    = {1707.05005},
  timestamp = {Mon, 15 Jul 2019 14:17:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/NarayananCVCLJ17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

% This file was created with Citavi 6.7.0.0
@article{Godec.31.12.2018,
 abstract = {Graphs are commonly used in different real-world applications. Social networks are large graphs of people that follow each other, biologists use graphs of protein interactions, while communication$\ldots$},
 author = {Godec, Primo{\v{z}}},
 year = {31.12.2018},
 title = {Graph Embeddings --- The Summary - Towards Data Science},
 url = {https://towardsdatascience.com/graph-embeddings-the-summary-cc6075aba007},
 urldate = {07.01.2021},
 journal = {Towards Data Science},
 file = {Godec 31.12.2018 - Graph Embeddings - The Summary:C\:\\Users\\Doo5i\\Documents\\Citavi 6\\Projects\\TemporalGraphEmbedding\\Citavi Attachments\\Godec 31.12.2018 - Graph Embeddings - The Summary.pdf:pdf}
}

@misc{Grover.03.07.2016,
 abstract = {Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.},
 author = {Grover, Aditya and Leskovec, Jure},
 date = {03.07.2016},
 title = {node2vec: Scalable Feature Learning for Networks},
 url = {https://arxiv.org/pdf/1607.00653},
 file = {Grover, Leskovec 03.07.2016 - node2vec Scalable Feature Learning:C\:\\Users\\Doo5i\\Documents\\Citavi 6\\Projects\\TemporalGraphEmbedding\\Citavi Attachments\\Grover, Leskovec 03.07.2016 - node2vec Scalable Feature Learning.pdf:pdf}
}

@proceedings{.2020,
 year = {2020},
 publisher = {ACM},
 isbn = {9781450368599}
}

@inproceedings{Beladev.2020,
 author = {Beladev, Moran and Rokach, Lior and Katz, Gilad and Guy, Ido and Radinsky, Kira},
 title = {tdGraphEmbed: Temporal Dynamic Graph-Level Embedding},
 publisher = {ACM},
 isbn = {9781450368599},
 year = {2020},
 doi = {10.1145/3340531.3411953}
}

% This file was created with Citavi 6.7.0.0
@article{Singer.2019,
 abstract = {In this work, we present a method for node embedding in temporal graphs. We propose an algorithm that learns the evolution of a temporal graph's nodes and edges over time and incorporates this dynamics in a temporal node embedding framework for different graph prediction tasks. We present a joint loss function that creates a temporal embedding of a node by learning to combine its historical temporal embeddings, such that it optimizes per given task (e.g., link prediction). The algorithm is initialized using static node embeddings, which are then aligned over the representations of a node at different time points, and eventually adapted for the given task in a joint optimization. We evaluate the effectiveness of our approach over a variety of temporal graphs for the two fundamental tasks of temporal link prediction and multi-label node classification, comparing to competitive baselines and algorithmic alternatives. Our algorithm shows performance improvements across many of the datasets and baselines and is found particularly effective for graphs that are less cohesive, with a lower clustering coefficient.},
 author = {Singer, Uriel and Guy, Ido and Radinsky, Kira},
 year = {2019},
 title = {Node Embedding over Temporal Graphs},
 url = {https://arxiv.org/pdf/1903.08889},
 pages = {4605--4612},
 journal = {IJCAI},
 doi = {10.24963/ijcai.2019/640},
 file = {Singer, Guy et al. 2019 - Node Embedding over Temporal Graphs:C\:\\Users\\Doo5i\\Documents\\Citavi 6\\Projects\\TemporalGraphEmbedding\\Citavi Attachments\\Singer, Guy et al. 2019 - Node Embedding over Temporal Graphs.pdf:pdf}
}

% This file was created with Citavi 6.7.0.0
@article{Schonemann.1966,
 abstract = {A solutionT of the least-squares problemAT=B +E, givenA andB so that trace (E$\prime$E)= minimum andT$\prime$T=I is presented. It is compared with a less general solution of the same problem which was given by Green [5]. The present solution, in contrast to Green's, is applicable to matricesA andB which are of less than full column rank. Some technical suggestions for the numerical computation ofT and an illustrative example are given.},
 author = {Sch{\"o}nemann, Peter H.},
 year = {1966},
 title = {A generalized solution of the orthogonal procrustes problem},
 pages = {1--10},
 volume = {31},
 number = {1},
 issn = {1860-0980},
 journal = {Psychometrika},
 doi = {10.1007/BF02289451},
 file = {Schönemann 1966 - A generalized solution:C\:\\Users\\Doo5i\\Documents\\Citavi 6\\Projects\\TemporalGraphEmbedding\\Citavi Attachments\\Schönemann 1966 - A generalized solution.pdf:pdf}
}

@misc{Ruder.15.09.2016,
 abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
 author = {Ruder, Sebastian},
 date = {15.09.2016},
 title = {An overview of gradient descent optimization algorithms},
 url = {https://arxiv.org/pdf/1609.04747},
 file = {Ruder 15.09.2016 - An overview of gradient descent:C\:\\Users\\Doo5i\\Documents\\Citavi 6\\Projects\\TemporalGraphEmbedding\\Citavi Attachments\\Ruder 15.09.2016 - An overview of gradient descent.pdf:pdf}
}

@misc{Mikolov.16.01.2013,
 abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
 author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
 date = {16.01.2013},
 title = {Efficient Estimation of Word Representations in Vector Space},
 url = {https://arxiv.org/pdf/1301.3781},
 file = {Mikolov, Chen et al. 16.01.2013 - Efficient Estimation of Word Representations:C\:\\Users\\Doo5i\\Documents\\Citavi 6\\Projects\\TemporalGraphEmbedding\\Citavi Attachments\\Mikolov, Chen et al. 16.01.2013 - Efficient Estimation of Word Representations.pdf:pdf}
}

@misc{Goldberg.15.02.2014,
 abstract = {The word2vec software of Tomas Mikolov and colleagues (https://code.google.com/p/word2vec/ ) has gained a lot of traction lately, and provides state-of-the-art word embeddings. The learning models behind the software are described in two research papers. We found the description of the models in these papers to be somewhat cryptic and hard to follow. While the motivations and presentation may be obvious to the neural-networks language-modeling crowd, we had to struggle quite a bit to figure out the rationale behind the equations.  This note is an attempt to explain equation (4) (negative sampling) in {\textquotedbl}Distributed Representations of Words and Phrases and their Compositionality{\textquotedbl} by Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado and Jeffrey Dean.},
 author = {Goldberg, Yoav and Levy, Omer},
 date = {15.02.2014},
 title = {word2vec Explained: deriving Mikolov et al.'s negative-sampling  word-embedding method},
 url = {https://arxiv.org/pdf/1402.3722},
 file = {Goldberg, Levy 15.02.2014 - word2vec Explained:C\:\\Users\\Doo5i\\Documents\\Citavi 6\\Projects\\TemporalGraphEmbedding\\Citavi Attachments\\Goldberg, Levy 15.02.2014 - word2vec Explained.pdf:pdf}
}

% This file was created with Citavi 6.7.0.0

@article{Goyal.2018,
 abstract = {Graphs, such as social networks, word co-occurrence networks, and communication networks, occur naturally in various real-world applications. Analyzing them yields insight into the structure of society, language, and different patterns of communication. Many approaches have been proposed to perform the analysis. Recently, methods which use the representation of graph nodes in vector space have gained traction from the research community. In this survey, we provide a comprehensive and structured analysis of various graph embedding techniques proposed in the literature. We first introduce the embedding task and its challenges such as scalability, choice of dimensionality, and features to be preserved, and their possible solutions. We then present three categories of approaches based on factorization methods, random walks, and deep learning, with examples of representative algorithms in each category and analysis of their performance on various tasks. We evaluate these state-of-the-art methods on a few common datasets and compare their performance against one another. Our analysis concludes by suggesting some potential applications and future directions. We finally present the open-source Python library we developed, named GEM (Graph Embedding Methods, available at https://github.com/palash1992/GEM), which provides all presented algorithms within a unified interface to foster and facilitate research on the topic.},
 author = {Goyal, Palash and Ferrara, Emilio},
 year = {2018},
 title = {Graph Embedding Techniques, Applications, and Performance: A Survey},
 url = {https://arxiv.org/pdf/1705.02801},
 pages = {78--94},
 volume = {151},
 issn = {09507051},
 journal = {Knowledge-Based Systems},
 doi = {10.1016/j.knosys.2018.03.022},
 file = {Goyal, Ferrara 2018 - Graph Embedding Techniques:C\:\\Users\\Doo5i\\Documents\\Citavi 6\\Projects\\TemporalGraphEmbedding\\Citavi Attachments\\Goyal, Ferrara 2018 - Graph Embedding Techniques.pdf:pdf}
}


@proceedings{Kraft.op.2003,
 year = {op. 2003},
 title = {CIKM 2003: Proceedings of the Twelfth ACM International Conference on Information {\&} Knowledge Management : November 3-8, 2003, New Orleans, Louisiana, USA},
 address = {New York, N.Y.},
 publisher = {{Association for Computing Machinery}},
 isbn = {1581137230},
 editor = {Kraft, Donald and Frieder, Ophir and Hammer, Joachim and Qureshi, Sajda and Seligman, Len},
 doi = {10.1145/956863}
}


@inproceedings{LibenNowell.op.2003,
 author = {Liben-Nowell, David and Kleinberg, Jon},
 title = {The link prediction problem for social networks},
 pages = {556},
 publisher = {{Association for Computing Machinery}},
 isbn = {1581137230},
 editor = {Kraft, Donald and Frieder, Ophir and Hammer, Joachim and Qureshi, Sajda and Seligman, Len},
 booktitle = {CIKM 2003},
 year = {op. 2003},
 address = {New York, N.Y.},
 doi = {10.1145/956863.956972},
 file = {Liben-Nowell, Kleinberg 2003 - The link prediction problem:C\:\\Users\\Doo5i\\Documents\\Citavi 6\\Projects\\TemporalGraphEmbedding\\Citavi Attachments\\Liben-Nowell, Kleinberg 2003 - The link prediction problem.pdf:pdf}
}

% This file was created with Citavi 6.7.0.0

@inproceedings{Ding.2001,
 author = {Ding, C.H.Q. and He, Xiaofeng and Zha, Hongyuan and Gu, Ming and Simon, H. D.},
 title = {A min-max cut algorithm for graph partitioning and data clustering},
 pages = {107--114},
 publisher = {{IEEE Computer Society}},
 isbn = {0-7695-1119-8},
 editor = {Cercone, Nick},
 booktitle = {Proceedings},
 year = {2001},
 address = {Los Alamitos, Calif},
 doi = {10.1109/ICDM.2001.989507},
 file = {https://ieeexplore.ieee.org/document/989507}
}












